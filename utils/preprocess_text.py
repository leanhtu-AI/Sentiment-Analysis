import regex as re
import string
import emoji
import demoji
import underthesea
from nltk import flatten
from utils.word_dict import replace_list

# Remove HTML code
def remove_HTML(text):
    return re.sub(r'<[^>]*>', '', text)

# Standardize unicode
def convert_unicode(text):
    char1252 = 'aÌ€|aÌ|aÌ‰|aÌƒ|aÌ£|Ã¢Ì€|Ã¢Ì|Ã¢Ì‰|Ã¢Ìƒ|Ã¢Ì£|ÄƒÌ€|ÄƒÌ|ÄƒÌ‰|ÄƒÌƒ|ÄƒÌ£|eÌ€|eÌ|eÌ‰|eÌƒ|eÌ£|ÃªÌ€|ÃªÌ|ÃªÌ‰|ÃªÌƒ|ÃªÌ£|iÌ€|iÌ|iÌ‰|iÌƒ|iÌ£|oÌ€|oÌ|oÌ‰|oÌƒ|oÌ£|Ã´Ì€|Ã´Ì|Ã´Ì‰|Ã´Ìƒ|Ã´Ì£|Æ¡Ì€|Æ¡Ì|Æ¡Ì‰|Æ¡Ìƒ|Æ¡Ì£|uÌ€|uÌ|uÌ‰|uÌƒ|uÌ£|Æ°Ì€|Æ°Ì|Æ°Ì‰|Æ°Ìƒ|Æ°Ì£|yÌ€|yÌ|yÌ‰|yÌƒ|yÌ£|AÌ€|AÌ|AÌ‰|AÌƒ|AÌ£|Ã‚Ì€|Ã‚Ì|Ã‚Ì‰|Ã‚Ìƒ|Ã‚Ì£|Ä‚Ì€|Ä‚Ì|Ä‚Ì‰|Ä‚Ìƒ|Ä‚Ì£|EÌ€|EÌ|EÌ‰|EÌƒ|EÌ£|ÃŠÌ€|ÃŠÌ|ÃŠÌ‰|ÃŠÌƒ|ÃŠÌ£|IÌ€|IÌ|IÌ‰|IÌƒ|IÌ£|OÌ€|OÌ|OÌ‰|OÌƒ|OÌ£|Ã”Ì€|Ã”Ì|Ã”Ì‰|Ã”Ìƒ|Ã”Ì£|Æ Ì€|Æ Ì|Æ Ì‰|Æ Ìƒ|Æ Ì£|UÌ€|UÌ|UÌ‰|UÌƒ|UÌ£|Æ¯Ì€|Æ¯Ì|Æ¯Ì‰|Æ¯Ìƒ|Æ¯Ì£|YÌ€|YÌ|YÌ‰|YÌƒ|YÌ£'
    charutf8 = 'Ã |Ã¡|áº£|Ã£|áº¡|áº§|áº¥|áº©|áº«|áº­|áº±|áº¯|áº³|áºµ|áº·|Ã¨|Ã©|áº»|áº½|áº¹|á»|áº¿|á»ƒ|á»…|á»‡|Ã¬|Ã­|á»‰|Ä©|á»‹|Ã²|Ã³|á»|Ãµ|á»|á»“|á»‘|á»•|á»—|á»™|á»|á»›|á»Ÿ|á»¡|á»£|Ã¹|Ãº|á»§|Å©|á»¥|á»«|á»©|á»­|á»¯|á»±|á»³|Ã½|á»·|á»¹|á»µ|Ã€|Ã|áº¢|Ãƒ|áº |áº¦|áº¤|áº¨|áºª|áº¬|áº°|áº®|áº²|áº´|áº¶|Ãˆ|Ã‰|áºº|áº¼|áº¸|á»€|áº¾|á»‚|á»„|á»†|ÃŒ|Ã|á»ˆ|Ä¨|á»Š|Ã’|Ã“|á»|Ã•|á»Œ|á»’|á»|á»”|á»–|á»˜|á»œ|á»š|á»|á» |á»¢|Ã™|Ãš|á»¦|Å¨|á»¤|á»ª|á»¨|á»¬|á»®|á»°|á»²|Ã|á»¶|á»¸|á»´'
    char1252 = char1252.split('|')
    charutf8 = charutf8.split('|')
    
    dic = {}
    for i in range(len(char1252)): dic[char1252[i]] = charutf8[i]
    return re.sub(
        r'aÌ€|aÌ|aÌ‰|aÌƒ|aÌ£|Ã¢Ì€|Ã¢Ì|Ã¢Ì‰|Ã¢Ìƒ|Ã¢Ì£|ÄƒÌ€|ÄƒÌ|ÄƒÌ‰|ÄƒÌƒ|ÄƒÌ£|eÌ€|eÌ|eÌ‰|eÌƒ|eÌ£|ÃªÌ€|ÃªÌ|ÃªÌ‰|ÃªÌƒ|ÃªÌ£|iÌ€|iÌ|iÌ‰|iÌƒ|iÌ£|oÌ€|oÌ|oÌ‰|oÌƒ|oÌ£|Ã´Ì€|Ã´Ì|Ã´Ì‰|Ã´Ìƒ|Ã´Ì£|Æ¡Ì€|Æ¡Ì|Æ¡Ì‰|Æ¡Ìƒ|Æ¡Ì£|uÌ€|uÌ|uÌ‰|uÌƒ|uÌ£|Æ°Ì€|Æ°Ì|Æ°Ì‰|Æ°Ìƒ|Æ°Ì£|yÌ€|yÌ|yÌ‰|yÌƒ|yÌ£|AÌ€|AÌ|AÌ‰|AÌƒ|AÌ£|Ã‚Ì€|Ã‚Ì|Ã‚Ì‰|Ã‚Ìƒ|Ã‚Ì£|Ä‚Ì€|Ä‚Ì|Ä‚Ì‰|Ä‚Ìƒ|Ä‚Ì£|EÌ€|EÌ|EÌ‰|EÌƒ|EÌ£|ÃŠÌ€|ÃŠÌ|ÃŠÌ‰|ÃŠÌƒ|ÃŠÌ£|IÌ€|IÌ|IÌ‰|IÌƒ|IÌ£|OÌ€|OÌ|OÌ‰|OÌƒ|OÌ£|Ã”Ì€|Ã”Ì|Ã”Ì‰|Ã”Ìƒ|Ã”Ì£|Æ Ì€|Æ Ì|Æ Ì‰|Æ Ìƒ|Æ Ì£|UÌ€|UÌ|UÌ‰|UÌƒ|UÌ£|Æ¯Ì€|Æ¯Ì|Æ¯Ì‰|Æ¯Ìƒ|Æ¯Ì£|YÌ€|YÌ|YÌ‰|YÌƒ|YÌ£',
        lambda x: dic[x.group()], text
    )

# Standardize accent typing
vowels_to_ids = {}
vowels_table = [
    ['a', 'Ã ', 'Ã¡', 'áº£', 'Ã£', 'áº¡', 'a' ],
    ['Äƒ', 'áº±', 'áº¯', 'áº³', 'áºµ', 'áº·', 'aw'],
    ['Ã¢', 'áº§', 'áº¥', 'áº©', 'áº«', 'áº­', 'aa'],
    ['e', 'Ã¨', 'Ã©', 'áº»', 'áº½', 'áº¹', 'e' ],
    ['Ãª', 'á»', 'áº¿', 'á»ƒ', 'á»…', 'á»‡', 'ee'],
    ['i', 'Ã¬', 'Ã­', 'á»‰', 'Ä©', 'á»‹', 'i' ],
    ['o', 'Ã²', 'Ã³', 'á»', 'Ãµ', 'á»', 'o' ],
    ['Ã´', 'á»“', 'á»‘', 'á»•', 'á»—', 'á»™', 'oo'],
    ['Æ¡', 'á»', 'á»›', 'á»Ÿ', 'á»¡', 'á»£', 'ow'],
    ['u', 'Ã¹', 'Ãº', 'á»§', 'Å©', 'á»¥', 'u' ],
    ['Æ°', 'á»«', 'á»©', 'á»­', 'á»¯', 'á»±', 'uw'],
    ['y', 'á»³', 'Ã½', 'á»·', 'á»¹', 'á»µ', 'y' ]
]

for i in range(len(vowels_table)):
    for j in range(len(vowels_table[i]) - 1):
        vowels_to_ids[vowels_table[i][j]] = (i, j)


def is_valid_vietnamese_word(word):
    chars = list(word)
    vowel_indexes = -1
    for index, char in enumerate(chars):
        x, y = vowels_to_ids.get(char, (-1, -1))
        if x != -1:
            if vowel_indexes == -1: vowel_indexes = index
            else:
                if index - vowel_indexes != 1: return False
                vowel_indexes = index
    return True


def standardize_word_typing(word):
    if not is_valid_vietnamese_word(word): return word
    chars = list(word)
    dau_cau = 0
    vowel_indexes = []
    qu_or_gi = False

    for index, char in enumerate(chars):
        x, y = vowels_to_ids.get(char, (-1, -1))
        if x == -1: continue
        elif x == 9:  # check qu
            if index != 0 and chars[index - 1] == 'q':
                chars[index] = 'u'
                qu_or_gi = True
        elif x == 5:  # check gi
            if index != 0 and chars[index - 1] == 'g':
                chars[index] = 'i'
                qu_or_gi = True

        if y != 0:
            dau_cau = y
            chars[index] = vowels_table[x][0]

        if not qu_or_gi or index != 1:
            vowel_indexes.append(index)

    if len(vowel_indexes) < 2:
        if qu_or_gi:
            if len(chars) == 2:
                x, y = vowels_to_ids.get(chars[1])
                chars[1] = vowels_table[x][dau_cau]
            else:
                x, y = vowels_to_ids.get(chars[2], (-1, -1))
                if x != -1: chars[2] = vowels_table[x][dau_cau]
                else: chars[1] = vowels_table[5][dau_cau] if chars[1] == 'i' else vowels_table[9][dau_cau]
            return ''.join(chars)
        return word

    for index in vowel_indexes:
        x, y = vowels_to_ids[chars[index]]
        if x == 4 or x == 8:  # Ãª, Æ¡
            chars[index] = vowels_table[x][dau_cau]
            return ''.join(chars)

    if len(vowel_indexes) == 2:
        if vowel_indexes[-1] == len(chars) - 1:
            x, y = vowels_to_ids[chars[vowel_indexes[0]]]
            chars[vowel_indexes[0]] = vowels_table[x][dau_cau]
        else:
            x, y = vowels_to_ids[chars[vowel_indexes[1]]]
            chars[vowel_indexes[1]] = vowels_table[x][dau_cau]
    else:
        x, y = vowels_to_ids[chars[vowel_indexes[1]]]
        chars[vowel_indexes[1]] = vowels_table[x][dau_cau]
    return ''.join(chars)


def standardize_sentence_typing(text):
    words = text.lower().split()
    for index, word in enumerate(words):
        cw = re.sub(r'(^\p{P}*)([p{L}.]*\p{L}+)(\p{P}*$)', r'\1/\2/\3', word).split('/')
        if len(cw) == 3: cw[1] = standardize_word_typing(cw[1])
        words[index] = ''.join(cw)
    return ' '.join(words)

def apply_replace_list(text, replace_list):
    for key, value in replace_list.items():
        # Ensure the key is surrounded by word boundaries to avoid partial matches
        pattern = r'\b' + re.escape(key) + r'\b'
        text = re.sub(pattern, value, text, flags=re.IGNORECASE)
    return demoji.replace(text, "")

# Remove unnecessary characters
def remove_unnecessary_characters(text):
    text = re.sub(r'[^\s\wÃ¡Ã áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã­Ã¬á»‰Ä©á»‹ÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µÄ‘ÃÃ€áº¢Ãƒáº Ä‚áº®áº°áº²áº´áº¶Ã‚áº¤áº¦áº¨áºªáº¬Ã‰Ãˆáººáº¼áº¸ÃŠáº¾á»€á»‚á»„á»†Ã“Ã’á»Ã•á»ŒÃ”á»á»’á»”á»–á»˜Æ á»šá»œá»á» á»¢ÃÃŒá»ˆÄ¨á»ŠÃšÃ™á»¦Å¨á»¤Æ¯á»¨á»ªá»¬á»®á»°Ãá»²á»¶á»¸á»´Ä_]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip() # Remove extra whitespace
    return text

def normalize_text(text):
    text = re.sub(r'(.)\1+', r'\1', text)
    return text

def preprocess(text, word_tokenize = None):
    text = text.strip()
    text = remove_HTML(text)
    text = convert_unicode(text) 
    text = standardize_sentence_typing(text)
    text = apply_replace_list(text, replace_list)
    text = normalize_text(text)
    tokens = text.split()
    text= underthesea.word_tokenize(" ".join(tokens), format="text")

    text = remove_unnecessary_characters(text)
    # return text.lower()
    return text

# # Test funtion
# text = preprocess("cÅ©nggggg khhhhhÃ´ng qqqqqqquÃ¡ğŸ˜")
# print(text)

# Viáº¿t nhá»¯ng hÃ m xá»­ lÃ­ cho chuáº©n hÃ³a tiáº¿ng viá»‡t  
# xá»­ lÃ­ unicode  
# Chuáº©n hÃ³a cÃ¢u( xÃ³a cÃ¡c tag html náº¿u cÃ³, xÃ³a emoji, xÃ³a khoáº£ng tráº¯ng thá»«a)  
# Chuáº©n hÃ³a tá»« (ktra tá»« tiáº¿ng viá»‡t, xÃ³a chá»¯ kÃ©o dÃ i, eg: Ä‘áº¹ppppp)  
# XÃ³a cÃ¡c dáº¥u thá»«a ( punctuation)